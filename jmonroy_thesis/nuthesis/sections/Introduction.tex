\hyphenation{ma-te-rials}
%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{ch:intro}

Over the last hundred years, exploration of nature at the atomic and subatomic scales has revealed the existence of the quantum world; several theories attempting to describe it have been created and many experiments to test them have been designed and executed.

This thesis explores three components of elementary particle physics. The theoretical component: the standard model (SM) of particle physics gathers the best understanding of nature that is consistent with the experimental data and although it is extremely successful, it is known that SM is not the final version of a theory of everything. The data analysis component: statistical methods have been developed in order to obtain the most from that experimental data. The instrumentation component: detection systems are under continuous research and development in order to extend their capabilities and sensitivity and improve their precision. 

The context of SM is presented in Chapter \ref{ch:theory}, starting with a description of the basic components of the matter, quarks and leptons, and how they interact to produce the universe as it is. The language used in this description is the quantum field theory based on the principles of the gauge invariance, which states that the function used in describing a system is invariant under certain transformations; from the physics point of view, that gauge invariance means that a physical system can be described by more than one mathematical model. Although the choice of the gauge could make, for instance, the mathematical treatment of the model more or less challenging, it does not have any effect on the observables of the physical system, \ie, a physical system is independent of the model used to describe it. Along the document natural units will be used with $c=\hbar=1$. 

Interactions in the SM are represented in terms of the exchange of particles, known as gauge bosons. For instance, the electromagnetic interaction between two electrically charged particles is modeled as the exchange of a photon, while the strong interaction between quarks is modeled as the exchange of gluons; hence, the photon and gluon are two of the gauge bosons. In addition, there is an interaction that explains the mass of the elementary particles; this is the interaction with the so-called Higgs field.    

In the SM, the Higgs boson is responsible for providing the mass to the elementary particles, and a fundamental part of characterization of the Higgs boson consists of finding the way it interacts with the rest of elementary particles, \ie, how the Higgs boson couples with other particles. In this thesis the coupling of the Higgs boson with the top quark is investigated; in particular, the search for the production of a Higgs boson in association with a single top quark (\tH) is considered; the focus is on the $H \to WW$ , $H \to \tau\tau$, and $H \to ZZ$ decay modes that provide leptonic signatures in the final state. This process is of special interest due to its sensitivity to the relative sign of the top-Higgs coupling and the vector bosons-Higgs coupling; in addition, \tH process is sensitive to charge-parity (CP) symmetry violation effects related with the Higgs boson. Thus, a description of the incorporation of the Higgs boson in the SM and the specifics of the \tH process are also presented in Chapter \ref{ch:theory}.               
The SM is a very successful theory, capable of explaining and making predictions about a vast number of natural phenomena, therefore, it is under constant testing looking for evidences that verifies its predictions or that reveals the existence of physics beyond it and highlight the road to this new physics. Currently, experiments held at CERN\footnote{CERN stand for Conseil Europ\'een pour la Recherche Nucl\'eaire} provide data from proton-proton collisions used to explore the SM. The source of the data used in this thesis is the Compact Muon Solenoid experiment (CMS) for which a description is presented in Chapter \ref{ch:cms}.

Thanks to increasing development in computing, tools like Monte Carlo (MC) generators, simulation and reconstruction algorithms and software allow for evaluating the theory predictions and comparing them with real data. MC generators are used to create a set of simulated data samples that reflect the theoretical principles and details of the process under investigation, thus, predictions are obtained from the numerical solution of the mathematical models; however, a direct comparison with the data obtained from the experiments is not possible because of a variety of factors, for instance, the presence of the detection systems. The effect of the detection systems can be simulated and attached to the MC data samples such that the resulting samples account for these effects.

Experimental data are also processed; given that the whole detector is composed of several subdetectors, the information coming from these subdetection systems is combined to reconstruct the features of the particles produced after the proton-proton collision. The process of matching the information from different subdetection systems is known as event reconstruction. The result of the event reconstruction is a set of objects that are identified with the particles expected in the final state and that are predicted by the theory; in the \tH process case, those final state particles are leptons and jets. Chapter \ref{ch:gensimreco} presents the details about the computational tools used in this thesis.  

The statistical tools used to treat the data samples are described in Chapter \ref{ch:stat}; these tools include the Boosted Decision Trees (BDT) method employed to discriminate signal and background events based on their features, and the statistical inference methods used to account for the uncertainties introduced in the analysis and to extract the upper limits on the \tH+\ttH\ production cross section. 

%The core of this thesis is presented in Chapters \ref{ch:analysis} and \ref{ch:pixel}.

In Chapter \ref{ch:analysis}, the search for the production of a Higgs boson in association with a single top quark (\tH) is presented. First, the features of the signal and background processes are described; then, the MC and data samples considered, and the strategies oriented to identify the physics objects are defined. The event selection proceeds in two steps; first, an event pre-selection based on the signal features is performed; later, the signal is extracted based on BDT discriminators. As a result, an upper limit on the \tH+\ttH\ production cross section is set. Finally, the  sensitivity to CP-mixing in \tH process is investigated and upper limits on the \tH+\ttH\ production cross section are set.   

In Chapter \ref{ch:pixel}, the upgrade of the CMS forward pixel detection system (FPix) is presented. The HEP group at University of Nebraska - Lincoln (UNL) played a leading role in the so-called Phase 1 FPix upgrade, serving as a FPix modules assembly site; the assembly process was designed as a production line composed of several stages among which the gluing and encapsulation stages are described in detail. These stages were implemented using a semi-automated pick-and-place robotic system integrating vision, vacuum, and dispensing subsystems. The employment of the semi-automated setup, capable of providing a precision in location of about 10 $\mu$m, provides uniformity and speed up the module production. The commissioning of the assembly site started from scratch in late 2012 and by mid 2015 the production yields reached the same level as other experienced assembly sites.

Chapter \ref{ch:Conclusions} presents the conclusions from both analysis and hardware development sides.

