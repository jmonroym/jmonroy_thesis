\hyphenation{ma-te-rials}
%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{ch:intro}

Along the last hundred years, exploration of nature at the atomic and subatomic scales has revealed the existence of the quantum world; several theories attempting to describe it have been created and many experiments to test it have been designed. Thus, challenges are three-fold; on the theoretical side, the standard model of particle physics (SM) gathers the best understanding of nature that is consistent with the experimental data and although it is extremely successful, it is known that SM is not the final version of a theory of everything; on the data analysis side, statistical methods have been developed in order to obtain the most from that experimental data; on the experimental side, detection systems are under continuous research and development in order to extend their capabilities and sensitivity and reduce their associated uncertainties. In this thesis, all three aspects are explored. 

The context of SM is presented in Chapter \ref{ch:theory}, starting with a description of the basic components of the matter, quarks and leptons, and how they interact to produce a universe as it is. The language used in this description is the quantum field theory based on the principles of the gauge invariance, which states that the function describing the energy of a system is invariant under certain transformations; from the physics point of view, that gauge invariance means that a physical system can be described by more than one mathematical model. Although the choice of the gauge could make, for instance, the mathematical treatment of the model more or less challenging, it does not have any effect on the observables of the physical system, \ie, a physical system is independent of the model used to describe it.

Interactions the SM are represented in terms of the exchange of particles, known as Gauge bosons; among the gauge bosons, the Higgs boson is responsible for providing the mass to the elementary particles, hence, a fundamental part of characterization of the Higgs boson consists of finding the way it interacts with the rest of elementary particles, \ie, how the Higgs boson couples with other particles. In this thesis the coupling of the Higgs boson with the top quark is investigated; in particular, the search for the production of a Higgs-boson in association with a single top-quark (\tH) is considered; the focus is on the $H \to WW$ , $H \to \tau\tau$, and $H \to ZZ$ decay modes that provide leptonic signatures in the final state. This process is of special interest due to its sensitivity to the relative sign of the top-Higgs coupling and the vector bosons-Higgs coupling; in addition, \tH process is sensitive to Charge-Parity (CP) symmetry violation effects related with the Higgs boson. Thus, a description of the incorporation of the Higgs boson in the SM and the specifics of the \tH process are also presented in Chapter \ref{ch:theory}.               

Despite the fact that the SM is a very successful theory, capable of explaining and make predictions about a vast amount of natural phenomena, by early 2012 a fundamental piece of it was missing; the Higgs boson had not been found and the verification of the theory was not complete. Its existence was postulated in the 1960s and several efforts to find it were made, like the experiments at the Fermi National accelerator Laboratory (Fermilab). The Higgs boson discovery was announced in July 2012 by the CMS and ATLAS experiments at CERN\footnote{CMS stand for Compact Muon Solenoid, ATLAS stand for A Toroidal LHC ApparatuS, CERN stand for Conseil Europ\'een pour la Recherche Nucl\'eaire} from proton-proton collision experiments. The data set used in this thesis were collected by the CMS experiment and the description of the experimental setup and the different subdetection systems is presented in Chapter \ref{ch:cms}.

Thanks to the increasing development in computing, tools like Monte Carlo (MC) generators, simulation and reconstruction algorithms and software, allow for evaluating the theory predictions and comparing them with real data. MC generators are used to create a set of data samples that reflects the theoretical principles and details of the process under investigation, thus, predictions are obtained from the numerical solution of the mathematical models; however, a direct comparison with the data obtained from the experiments is not possible because of a variety of factors, for instance, the presence of the detection systems. The effect of the detection systems can be simulated and attached to the MC data samples such that the resulting samples account for these effects.

Experimental data are also processed; given that the whole detector is composed of several subdetectors, the information coming from these subdetection systems is combined to reconstruct the features of the particles produced after the proton-proton collision. The process of matching the information from different subdetection systems is known as event reconstruction. The result of the event reconstruction is a set of objects that are identified with the particles expected in the final state and that are predicted by the theory; in the \tH process case, those final state particles are leptons and jets. Chapter \ref{ch:gensimreco} presents the details about the computational tools used in this thesis.  

The statistical tools used to treat the data samples are described in Chapter \ref{ch:stat}; these tools include the Boosted Decision Trees (BDT) method employed to discriminate signal and background events based on their features, and the statistical inference methods used to account for the uncertainties introduced in the analysis and to extract the asymptotic limits on the \tH+\ttH\ production cross section. 

%The core of this thesis is presented in Chapters \ref{ch:analysis} and \ref{ch:pixel}.

In Chapter \ref{ch:analysis}, the search for the production of a Higgs-boson in association with a single top-quark (\tH) is presented. First, the features of the signal and background processes are described; then, the MC and data samples considered, and the strategies oriented to identify the physics objects are defined. The event selection proceeds in two steps; first, an event pre-selection based on the signal features is performed; later, the signal is extracted based on BDT discriminators, and upper limits on the \tH+\ttH\ production cross section are set. Finally, the  sensitivity to CP-mixing in \tH process is investigated and upper limits on the \tH+\ttH\ production cross section are set.   

In Chapter \ref{ch:pixel}, the upgrade of the CMS forward pixel detection system (FPix) is presented. The HEP group at University of Nebraska - Lincoln (UNL), played a leading role in the so called Phase 1 FPix upgrade, serving as a FPix modules assembly site; the assembly process was designed as a production line composed of several stages among which the gluing and encapsulation stages are described in detail. These stages were implemented using a semi automated pick-and-place robotic system integrating vision, vacuum, and dispensing subsystems. The employment of the semi automated setup, capable to provide a precision in motion of about 10 $\mu$m, endow of uniformity and speed up the module production. The commissioning of the assembly site started from scratch in late 2012 and by mid 2015 the production yields reached the same level as other experienced assembly sites.

Chapter \ref{ch:Conclusions} presents the conclusions from both analysis and hardware development sides.

